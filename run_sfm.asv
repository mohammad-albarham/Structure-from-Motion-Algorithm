
% RUN_SFM - Main script for Structure from Motion (SfM)
% Usage: run_sfm(<dataset number>)

% reset and load data
% clc; close all;
% run('C:\Users\pain\Desktop\CV_project\vlfeat-0.9.21-bin\vlfeat-0.9.21\toolbox\vl_setup')
% Get dataset info by providing dataset input

% Control random number generator - to get consistant resutls
rng(42)

%%
% Extract dataset info
[K, img_names, init_pair, pixel_threshold] = get_dataset_info(2);

%%
% Step 1: Calculate the relative Orientation

% Number of images
N = length(img_names);

% Initialize rotations and translations for relative poses
Rn = cell(1, N-1); % Relative rotations, normalised

desc_im = cell(1,N); 
feat_im = cell(1,N);

for n=1:N-1
    % Step 2: Compute the features using SIFT, extract the matches and the corresponding points
    % Load the images 
    im1 = imread(img_names{n});
    im2 = imread(img_names{n+1});
    
    % Pipeline for extracting the featuers 
    [x1, x2, ~, fA, dA] = feature_extraction(im1,im2);
    
    feat_im{n} = fA; 
    desc_im{n} = dA;

    % Step3: Estimate E robust using RANSAC
    % Define the pixel threhold 
    eps = pixel_threshold * 2 / (K(1,1) + K(2,2)); % Normalize threshold
    
    % Get the estimate_E_robust
    [E_ransac, indices] = estimate_E_robust(x1, x2, eps, K);
   
    % Step 4: Triangulate the points and Check for Cheirality Condition using Triangulation:
    [X,P] = Cheirality_triangulate(x1,x2, indices,K,E_ransac);
     
    % Save relative pose
    Rn{n} = inv(K) * P{2}(1:3, 1:3); % Extract rotation from P2

    % Step 5: Visualization
    figure;
    plot3(X(1, :), X(2, :), X(3, :), '.', 'MarkerSize', 10);
    hold on;
    plotcams(P); % Plot cameras
    xlabel('x'); ylabel('y'); zlabel('z');
    title('Relative plot of 3D points');
    axis equal;
    grid on;
    hold off;

end

%%
% Step 2: Upgrade to absolute Rotations
tot = length(Rn);

P{1} = K* [eye(3), zeros(3, 1)];

R_abs_i = cell(1, N);
R_abs_i{1} = eye(3,3);

for k=1:tot
    % Calculate the rotation translation 
    R_abs_i{k+1} = Rn{1,k} * R_abs_i{k};
end

%% Step 3: Reconstruct initial 3D points from initial image pair 

% get the 3D points from the suggested pair 
% Load the images 
im1 = imread(img_names{init_pair(1)});
im2 = imread(img_names{init_pair(2)});

% Pipeline for extracting the featuers, 

[x1, x2, desc_X, ~,~] = feature_extraction(im1,im2);

% Step: Estimate E robust using RANSAC

% Define the pixel threhold 
eps = pixel_threshold * 2 / (K(1,1) + K(2,2)); % Normalize threshold

% Get the estimate_E_robust
[E_ransac, indices] = estimate_E_robust(x1, x2, eps, K);

% Save descriptors for future use "Only inliers"
desc_X = desc_X(:,indices);
save('desc_X.mat', 'desc_X'); % Save to a mat file

% Triangulate points using relative pose

[X_0,P] = Cheirality_triangulate(x1,x2, indices,K,E_ransac);


P_X_0 = P{2};


% Rotate the initial 3D points to the world coordinate
X_wc = R_abs_i{init_pair(1)}' * X_0(1:3,:);

% Step 1: Compute Center of Gravity
X_mean = mean(X_wc, 2); % 3x1 mean position

% Step 2: Compute Distances
distances = vecnorm(X_wc - X_mean, 2, 1); % Euclidean distances

% Step 3: Compute Threshold
q90 = quantile(distances, 0.9); % 90th percentile
threshold = 5 * q90;           % 5 times the 90% quantile

% Step 4: Filter Outliers
inliers = distances <= threshold;           % Logical indices for inliers
X_wc_filtered = X_wc(:, inliers);           % Filtered 3D points

% Step 5: Visualization
figure;
plot3(X_wc_filtered(1, :), X_wc_filtered(2, :), X_wc_filtered(3, :), '.', 'MarkerSize', 10);
hold on;
plotcams(P); % Plot cameras
xlabel('x'); ylabel('y'); zlabel('z');
title('Filtered 3D Points and Cameras');
axis equal;
grid on;
hold off;


% ------------------------------------------------------------------------
%%
% Step 4:

% Establish correspondences between i and 3D points (using desc X),
% Number of images
N = length(img_names);
T_best = cell(1,N);

T_best{1} = zeros(3,1);
for n = 1:N-1
     
    [matches_2d_3d, ~] = vl_ubcmatch(desc_X, desc_im{n});

    % Get the 2D points correspondences on each images' pair
    xA = feat_im{n}(1:2 , matches_2d_3d(1 ,:));

    %TODO: Solve the problem here
    x1 = [xA; ones(1,length(xA))];

    % Normalize the points
    xsn1 = inv(K) * x1;

    % Use triangulated 3D points
    X_0_0 = X_wc(1:3, :);

    Xs = inv(K) * X_0_0(:,matches_2d_3d(1 ,:));   % 3D points (Nx3)
    Xsn = [Xs; ones(1,length(Xs))];
        
    translation_threshold = 3 * pixel_threshold / K(1,1);
  
    % The normalized coordinates is used here 
    T_best{n+1} = estimate_T_robust(xsn1, Xsn, R_abs_i{n}, 0.5, zeros(1,3), K);

end

%%

P_test = cell(1,N);

for i=1:9 
    P_test{i} = K * [R_abs_i{i} T_best{i}]
end

figure();
plotcams(P_test)

%%
% %%

% Generate synthetic 3D points
Xs_gt = [rand(3, 100); ones(1, 100)]; % Homogeneous coordinates
T_gt = [1; 2; 3];
R_gt = eye(3);

% Project to 2D
xs_gt = (R_gt * Xs_gt(1:3, :) + T_gt); % Project 3D points
xs_gt = xs_gt ./ xs_gt(3, :); % Normalize

% Add noise
xs_noisy = xs_gt + 0.01 * randn(size(xs_gt));

T_best = estimate_T_robust(xsn1, Xsn, R_gt, 0.5, zeros(1,3));

% Estimate translation
disp('Estimated T:');
disp(T_est);
disp('Ground Truth T:');
disp(T_gt);



%

%%
% Step 5: Optimize the translation vectors

% Optimization parameters
mu = 1e-3;
max_iterations = 100;
tolerance = 1e-6;

% Optimize translations
%  [T1_refined, T2_refined, error] = optimize_translations(K, R_abs_i{1}, R_abs_i{2}, T_abs_i{1}, T_abs_i{2}, [X_wc; ones(1,length(X_wc))], x1, x2, mu, max_iterations, tolerance);


%% 
% Step 6: Triangulate points for all pairs (i, i + 1) and visualize 3D points + cameras

